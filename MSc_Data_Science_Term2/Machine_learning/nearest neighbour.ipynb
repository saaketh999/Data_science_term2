{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nearest neighbor classifier \n",
    "\n",
    "**Aim:** Visualise the decision surface of a k-NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "\n",
    "A) Make a function `plot(X,y=None)` that plots a scatter plot of a two dimensional data matrix `X` coloring the instances according to the one dimensional array `y` if it is not `None`.\n",
    "\n",
    "\n",
    "B) Make a function `X,y = make_data(n_samples)` to create a data set for a binary classification problem.\n",
    "The function outputs a two dimensional data matrix `X` and a corresponding one dimensional class vector `y`. \n",
    "\n",
    "You can use of the scikit function [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html). \n",
    "\n",
    "Study the function parameters. \n",
    "\n",
    "In the following you can use the configuration:\n",
    "\n",
    "```\n",
    "        n_features=2, \n",
    "        n_informative=2, \n",
    "        n_redundant=0, \n",
    "        n_repeated=0,\n",
    "        n_classes=2, \n",
    "        n_clusters_per_class=2,\n",
    "        class_sep=.7,\n",
    "        flip_y=0.2,\n",
    "        weights=[0.5,0.5]\n",
    "```\n",
    "\n",
    "**Additional references:** Faizan Ahemad, [Generating Synthetic Classification Data using Scikit](https://towardsdatascience.com/https-medium-com-faizanahemad-generating-synthetic-classification-data-using-scikit-1590c1632922), Towards Data Science, 2019\n",
    "\n",
    "\n",
    "\n",
    "C) Use the scikit function [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train%20test#sklearn.model_selection.train_test_split) to create a data matrix (and corresponding target vector) for training and for test. \n",
    "\n",
    "Study the function parameters. \n",
    "\n",
    "Visualize the following:\n",
    "```\n",
    "plot(X_train,y_train)\n",
    "plot(X_test,y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot(X,y=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def make_data(n_samples):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X,y = make_data(n_samples=1000)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError() \n",
    "\n",
    "plot(X_train,y_train)\n",
    "plot(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "Make a function `y_pred = predict_knn(X_test, X_train, y_train, k)` that outputs a one dimensional array containing the class predicted for `X_test` by the k-nearest neighbor algorithm for `k` neighbors over the data in `X_train, y_train`.\n",
    "\n",
    "Do not use directly the scikit function [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n",
    "\n",
    "Useful auxiliary functions to build `predict_knn` are:\n",
    "\n",
    "- `distance(X1,X2)` in `scipy.spatial`\n",
    "- `argsort(A)` in `numpy`\n",
    "- `mode` in `scipy.stats`\n",
    "\n",
    "Study the use of these function in the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# distance\n",
    "\n",
    "from scipy.spatial import distance\n",
    "data_mtx1 = [(1, 1),(2, 1),(1, 2),(2, 2)]\n",
    "data_mtx2 = [(10, 10),(20, 10),(10, 20),(20, 20)]\n",
    "D1 = distance.cdist(data_mtx1, data_mtx1)\n",
    "D2 = distance.cdist(data_mtx1, data_mtx2)\n",
    "print('Distance of each sample from other samples in the same data matrix')\n",
    "print(D1)\n",
    "print()\n",
    "print('Distance of each sample in data_mtx1 from other samples in data_mtx2')\n",
    "print(D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# argsort \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "mtx = np.random.randint(10, size=(5,3))\n",
    "print('Original data')\n",
    "print(mtx)\n",
    "print()\n",
    "print('the sorted indices, i.e. considering the elements in the order specified by the indices one obtains a sorted array')\n",
    "ids = np.argsort(mtx, axis=1)\n",
    "print(ids)\n",
    "print('Make sure to understand the notion of axis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# mode\n",
    "import scipy as sp\n",
    "import scipy.stats \n",
    "\n",
    "mtx = np.random.randint(5, size=(3,10))\n",
    "print('Original data')\n",
    "print(mtx)\n",
    "print()\n",
    "print('the mode, i.e. most frequent element')\n",
    "print(sp.stats.mode(mtx, axis=1))\n",
    "\n",
    "A,B = sp.stats.mode(mtx, axis=1)\n",
    "print('Values')\n",
    "print(A)\n",
    "print()\n",
    "print('Counts')\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def predict_knn(X_test, X_train, y_train, k):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "A) Make a function `make_grid(X, n_samples)` that outputs a two dimensional array containing in total `n_samples` instances in $\\mathcal{R}^2$ arranged as a regular grid. Use the input data matrix `X` to extract the boundaries (i.e. the min, max values for each axis).\n",
    "\n",
    "B) Make a function `plot_decision_surface(X,y,X_grid,yg)` that plots a scatter plot for the data matrix `X` and the grid points in the data matrix `X_grid` using `y` and `yg` respectively to color the instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def make_grid(X, n_samples):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_decision_surface(X,y,X_grid,yg):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X_grid = make_grid(X_train, n_samples=4000)\n",
    "plot(X_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = predict_knn(X_grid, X_train, y_train, k=1)\n",
    "plot(X_grid,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "yg = predict_knn(X_grid, X_train, y_train, k=1)\n",
    "plot_decision_surface(X_test,y_test,X_grid,yg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "yg = predict_knn(X_grid, X_train, y_train, k=7)\n",
    "plot_decision_surface(X_test,y_test,X_grid,yg)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
